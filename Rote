范数：0范数，向量中非零元素的个数；1范数，为绝对值之和；2范数，就是通常意义上的模。

1范数和0范数可以实现稀疏，1因具有比L0更好的优化求解特性而被广泛应用。
L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的正则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，
它不会让它等于0，而是接近于0，这里是有很大的区别的哦；所以大家比起1范数，更钟爱2范数。

One-Hot coding(独热编码):直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。
在机器学习中对于离散型的分类型的数据，需要对其进行数字化比如说性别这一属性，只能有男性或者女性或者其他这三种值，如何对这三个值进行数字化表达？一种简单
的方式就是男性为0，女性为1，其他为2，这样做有什么问题？使用上面简单的序列对分类值进行表示后，进行模型训练时可能会产生一个问题就是特征的因为数字值的不同
而影响模型的训练效果，在模型训练的过程中不同的值使得同一特征在样本中的权重可能发生变化，假如直接编码成1000，是不是比编码成1对模型的的影响更大。为了解决
上述的问题，使训练过程中不受到因为分类值表示的问题对模型产生的负面影响，引入独热码对分类型的特征进行独热码编码。

为什么用CNN提取特征？
答：1.由于卷积和池化计算的性质，使得图像中的平移部分对于最后的特征向量是没有影响的。从这一角度说，提取到的特征更不容易过拟合。而且由于平移不变性，所以
平移字符进行变造是无意义的，省去了再对样本进行变造的过程。
2.CNN抽取出的特征要比简单的投影、方向，重心都要更科学。不会让特征提取成为最后提高准确率的瓶颈、天花板
3.可以利用不同的卷积、池化和最后输出的特征向量的大小控制整体模型的拟合能力。在过拟合时可以降低特征向量的维数，在欠拟合时可以提高卷积层的输出维数。相比
于其他特征提取方法更加灵活

CNN+SVM算法流程：整理训练网络的数据 -> 建立卷积神经网络 -> 将数据代入进行训练 -> 保存训练好的模型 -> 把数据代入模型获得特征向量 -> 用特征向量代替
原本的X送入SVM训练 -> 测试时同样将X转换为特征向量之后用SVM预测，获得结果
